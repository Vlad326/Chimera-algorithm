import cv2
import numpy as np
import os
import time
from datetime import datetime
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed

class DatasetCreator:
    def __init__(self):
        self.images_dir = "dataset_fast"
        self.video_dir = "videos_fast"
        os.makedirs(self.images_dir, exist_ok=True)
        os.makedirs(self.video_dir, exist_ok=True)
        self.cap = None
        self.writing = False
        self.frame_count = 0

    @staticmethod
    def calculate_similarity_numba(gray1, gray2):
        """–£—Å–∫–æ—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Numba"""
        if gray1.size == 0 or gray2.size == 0:
            return float('inf')
        
        diff = np.abs(gray1.astype(np.int32) - gray2.astype(np.int32))
        return np.sum(diff)

    def calculate_similarity(self, frame1, frame2):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        if frame1 is None or frame2 is None:
            return float('inf')

        # –ë—ã—Å—Ç—Ä–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ grayscale –∏ —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
        
        # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è (–º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å)
        scale_factor = 0.25
        if scale_factor < 1.0:
            new_size = (int(gray1.shape[1] * scale_factor), int(gray1.shape[0] * scale_factor))
            gray1 = cv2.resize(gray1, new_size, interpolation=cv2.INTER_AREA)
            gray2 = cv2.resize(gray2, new_size, interpolation=cv2.INTER_AREA)

        return self.calculate_similarity_numba(gray1, gray2)

    def select_unique_frames_fast(self, video_path, num_frames):
        """–°–£–ü–ï–† –£–°–ö–û–†–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è –≤—ã–±–æ—Ä–∞ –∫–∞–¥—Ä–æ–≤"""
        print(f"\n=== –£–°–ö–û–†–ï–ù–ù–´–ô –í–´–ë–û–† {num_frames} –ö–ê–î–†–û–í ===")
        
        start_time = time.time()
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–∏–¥–µ–æ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print("–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ!")
            return
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        print(f"–í—Å–µ–≥–æ –∫–∞–¥—Ä–æ–≤: {total_frames}, FPS: {fps:.1f}")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —à–∞–≥ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞ –∫–∞–¥—Ä–æ–≤
        frame_skip = max(1, total_frames // (num_frames * 10))
        print(f"–ê–≤—Ç–æ–ø—Ä–æ–ø—É—Å–∫: –∫–∞–∂–¥—ã–π {frame_skip}-–π –∫–∞–¥—Ä")
        
        # –ß–∏—Ç–∞–µ–º –í–°–ï –∫–∞–¥—Ä—ã –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥
        frames = []
        frame_indices = []
        
        print("–ë—ã—Å—Ç—Ä–æ–µ —á—Ç–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤...")
        for i in range(0, total_frames, frame_skip):
            cap.set(cv2.CAP_PROP_POS_FRAMES, i)
            ret, frame = cap.read()
            if ret:
                frames.append(frame)
                frame_indices.append(i)
            if len(frames) >= num_frames * 5:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –±—É—Ñ–µ—Ä
                break
        
        cap.release()
        read_time = time.time() - start_time
        print(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(frames)} –∫–∞–¥—Ä–æ–≤ –∑–∞ {read_time:.2f} —Å–µ–∫")
        
        if len(frames) < num_frames:
            print(f"–û—à–∏–±–∫–∞: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞–¥—Ä–æ–≤! –ù—É–∂–Ω–æ {num_frames}, –µ—Å—Ç—å {len(frames)}")
            return
        
        # –ë—ã—Å—Ç—Ä—ã–π –æ—Ç–±–æ—Ä —Å–∞–º—ã—Ö —Ä–∞–∑–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤
        print("–ë—ã—Å—Ç—Ä—ã–π –æ—Ç–±–æ—Ä –∫–∞–¥—Ä–æ–≤...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        selected_indices = []
        step = max(1, len(frames) // num_frames)
        
        for i in range(0, len(frames), step):
            if len(selected_indices) < num_frames:
                selected_indices.append(i)
        
        # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –∫–∞–¥—Ä–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ
        if len(selected_indices) < num_frames:
            remaining = num_frames - len(selected_indices)
            available_indices = [i for i in range(len(frames)) if i not in selected_indices]
            selected_indices.extend(np.random.choice(available_indices, remaining, replace=False))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã
        print("–ë—ã—Å—Ç—Ä–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ...")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for i, idx in enumerate(selected_indices):
            img_filename = os.path.join(self.images_dir, f"fast_{timestamp}_{i:04d}.jpg")
            cv2.imwrite(img_filename, frames[idx])
        
        total_time = time.time() - start_time
        print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(selected_indices)} –∫–∞–¥—Ä–æ–≤ –∑–∞ {total_time:.2f} —Å–µ–∫")
        print(f"–°–∫–æ—Ä–æ—Å—Ç—å: {len(frames)/read_time:.1f} –∫–∞–¥—Ä–æ–≤/—Å–µ–∫")
        
        return selected_indices

    def select_unique_frames_parallel(self, video_path, num_frames):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –º–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω—ã—Ö —Å–∏—Å—Ç–µ–º"""
        print(f"\n=== –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–´–ô –í–´–ë–û–† {num_frames} –ö–ê–î–†–û–í ===")
        
        start_time = time.time()
        
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        frame_skip = max(1, total_frames // (num_frames * 5))
        
        # –ß–∏—Ç–∞–µ–º –∫–∞–¥—Ä—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        frames = []
        indices_to_read = list(range(0, total_frames, frame_skip))[:num_frames * 3]
        
        def read_frame(pos):
            cap_local = cv2.VideoCapture(video_path)
            cap_local.set(cv2.CAP_PROP_POS_FRAMES, pos)
            ret, frame = cap_local.read()
            cap_local.release()
            return frame if ret else None
        
        print("–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤...")
        with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:
            future_to_index = {executor.submit(read_frame, pos): pos for pos in indices_to_read}
            
            for future in as_completed(future_to_index):
                frame = future.result()
                if frame is not None:
                    frames.append(frame)
                if len(frames) % 50 == 0:
                    print(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(frames)} –∫–∞–¥—Ä–æ–≤...")
        
        cap.release()
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π –æ—Ç–±–æ—Ä
        selected_indices = list(range(0, len(frames), max(1, len(frames) // num_frames)))[:num_frames]
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        for i, idx in enumerate(selected_indices):
            if idx < len(frames):
                img_filename = os.path.join(self.images_dir, f"parallel_{timestamp}_{i:04d}.jpg")
                cv2.imwrite(img_filename, frames[idx])
        
        total_time = time.time() - start_time
        print(f"–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.2f} —Å–µ–∫")
        
        return selected_indices

    def ultra_fast_selection(self, video_path, num_frames):
        """–°–ê–ú–ê–Ø –ë–´–°–¢–†–ê–Ø –≤–µ—Ä—Å–∏—è - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑, –±–µ—Ä–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ"""
        print(f"\n‚ö° –£–õ–¨–¢–†–ê–ë–´–°–¢–†–´–ô –û–¢–ë–û–† {num_frames} –ö–ê–î–†–û–í ‚ö°")
        
        start_time = time.time()
        
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # –í—ã—á–∏—Å–ª—è–µ–º —à–∞–≥ –¥–ª—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞
        step = max(1, total_frames // num_frames)
        selected_indices = list(range(0, total_frames, step))[:num_frames]
        
        print(f"–û—Ç–±–∏—Ä–∞–µ–º –∫–∞–∂–¥—ã–π {step}-–π –∫–∞–¥—Ä –∏–∑ {total_frames}")
        
        # –ß–∏—Ç–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        saved_count = 0
        
        for i, frame_pos in enumerate(selected_indices):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)
            ret, frame = cap.read()
            if ret:
                img_filename = os.path.join(self.images_dir, f"ultrafast_{timestamp}_{i:04d}.jpg")
                cv2.imwrite(img_filename, frame)
                saved_count += 1
            
            if saved_count % 50 == 0:
                print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –∫–∞–¥—Ä–æ–≤...")
        
        cap.release()
        
        total_time = time.time() - start_time
        print(f"‚ö° –£–õ–¨–¢–†–ê–ë–´–°–¢–†–û! {saved_count} –∫–∞–¥—Ä–æ–≤ –∑–∞ {total_time:.2f} —Å–µ–∫")
        print(f"–°–∫–æ—Ä–æ—Å—Ç—å: {saved_count/max(0.1, total_time):.1f} –∫–∞–¥—Ä–æ–≤/—Å–µ–∫")
        
        return saved_count

def main():
    creator = DatasetCreator()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Å–µ –º–µ—Ç–æ–¥—ã
    video_file = 'video.avi'
    
    if not os.path.exists(video_file):
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {video_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return
    
    print("–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ —É—Å–∫–æ—Ä–µ–Ω–∏—è:")
    print("1 - –°—É–ø–µ—Ä –±—ã—Å—Ç—Ä—ã–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)")
    print("2 - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π (–º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π)")
    print("3 - –£–ª—å—Ç—Ä–∞–±—ã—Å—Ç—Ä—ã–π (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å)")
    
    choice = input("–í–∞—à –≤—ã–±–æ—Ä (1-3): ").strip()
    
    start_total = time.time()
    
    if choice == "1":
        creator.select_unique_frames_fast(video_file, 125)
    elif choice == "2":
        creator.select_unique_frames_parallel(video_file, 125)
    elif choice == "3":
        creator.ultra_fast_selection(video_file, 125)
    else:
        print("–ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—å—Ç—Ä–∞–±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        creator.ultra_fast_selection(video_file, 125)
    
    total_time = time.time() - start_total
    print(f"\nüéâ –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")

if __name__ == "__main__":
    main()
